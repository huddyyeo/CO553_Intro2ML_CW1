{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6dY4sYN5BhnF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('clean_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure what you guys are working on but I'm leaving this here since you added it\n",
    "def find_split(data):\n",
    "    \n",
    "    split_attribute,split_value = None, None\n",
    "    \n",
    "    #entropy of data\n",
    "    H_data = None\n",
    "    \n",
    "    # Sort\n",
    "    signal_data = np.sort(data[:-1], axis=1)\n",
    "    \n",
    "    # Create array of unique datapoints    \n",
    "    for room in signal_data:\n",
    "        split_points = np.unique(rooms)\n",
    "\n",
    "    return split_attribute,split_value \n",
    "\n",
    "\n",
    "def information_gain():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first method: following the algo given in the coursework instructions\n",
    "\n",
    "def DECISION_TREE_LEARNING(data,depth=0):\n",
    "    '''\n",
    "    Recursive tree algorithm, simply run the function on the data\n",
    "    It will return tree, depth as described in the coursework instructions \n",
    "    '''\n",
    "    #if all samples have the same label\n",
    "    if len(np.unique(data.values[:,-1]))==1:\n",
    "\n",
    "        #return a leaf node\n",
    "        node=tree_node(label=data.values[0,-1],depth=depth+1)\n",
    "        return node,depth+1\n",
    "\n",
    "    else:\n",
    "\n",
    "        #find split\n",
    "        #split attribute: router from [1,...,6]\n",
    "        #split_value: router value        \n",
    "        split_attribute,split_value=find_split(data)\n",
    "\n",
    "        #split data\n",
    "        l_data=data[data[:,split_attribute]<=split_value]\n",
    "        r_data=data[data[:,split_attribute]>split_value]\n",
    "\n",
    "        #recursively callthe function\n",
    "        l_branch,l_depth=DECISION_TREE_LEARNING(l_data,depth+1)\n",
    "        r_branch,r_depth=DECISION_TREE_LEARNING(r_data,depth+1)\n",
    "        \n",
    "        #here we create a non-leaf node, it has split value and attribute as well as 2 children\n",
    "        node=tree_node(split_value=split_value,split_attribute=split_attribute,left=l_branch,right=r_branch,depth=depth+1)\n",
    "        return node,max(l_depth,r_depth)\n",
    "\n",
    "    def get_depth(self):\n",
    "            max_depth=[self.depth]\n",
    "            if self.left_child():\n",
    "                max_depth.append(self.left_child.get_depth())\n",
    "            if self.right_child():\n",
    "                max_depth.append(self.right_child.get_depth())                 \n",
    "            return max(max_depth)\n",
    "                 \n",
    "    def test(self,data):\n",
    "        #runs through the code and returns result of one point\n",
    "        if self.label:\n",
    "            return self.label\n",
    "        else:\n",
    "            if #data attribute > self.split_value\n",
    "                 #subset data based on the split value and attribute\n",
    "                 return self.right_child.test(data_new)\n",
    "            else:\n",
    "                 return self.left_child.test(data_new)\n",
    "        \n",
    "    def visualise(self):\n",
    "        #visualisation\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self):\n",
    "        #evaluation\n",
    "        pass         \n",
    "\n",
    "class tree_node:\n",
    "    def __init__(self,split_value=None,split_attribute=None,leaf=False,label=None,left=None,right=None,depth=0):\n",
    "        self.label=label\n",
    "        self.split_value=split_value\n",
    "        self.split_attribute=split_attribute\n",
    "        self.left_child=left\n",
    "        self.right_child=right\n",
    "        self.depth=depth        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDfXT0lO7vn2"
   },
   "outputs": [],
   "source": [
    "#second method: a more intuitive method that makes sense\n",
    "\n",
    "class binarySearchTree:\n",
    "    def __init__(self, samples, depth, label = None, attributes_used=[]):\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.samples = samples\n",
    "        self.depth = depth+1\n",
    "        self.label = label\n",
    "        self.attributes_used = attributes_used\n",
    "        self.split_value = None\n",
    "        self.split_label = None\n",
    "        \n",
    "        if len(np.unique(data.values[:,-1]))==1: #assuming last column is for labels\n",
    "            self.label = label\n",
    "        \n",
    "        else:\n",
    "            #not all samples have same label, do a split\n",
    "            # split attribute: router from [1,...,6]\n",
    "            # split_value: router value\n",
    "            split_attribute, self.split_value = find_split(data, self.attributes_used) \n",
    "            self.attributes_used.append(split_attribute) \n",
    "        \n",
    "\n",
    "\n",
    "            #split data into data1 and data2 based on the split value\n",
    "            #code to be completed\n",
    "            l_data = []\n",
    "            r_data = []\n",
    "\n",
    "            l_data=data[data[:,split_attribute]<=split_value]\n",
    "\n",
    "            r_data=data[data[:,split_attribute]>split_value]\n",
    "             \n",
    "            #recursively search the tree, branching into 2 \n",
    "            self.left_child=binarySearchTree(l_data, self.depth, attributes_used)\n",
    "            self.right_child=binarySearchTree(r_data, self.depth, attributes_used)\n",
    "\n",
    "            #return label, max(self.left_child.get_depth(), self.right_child.get_depth())\n",
    "\n",
    "        \n",
    "    def get_depth(self):\n",
    "            max_depth=[self.depth]\n",
    "            if self.left_child():\n",
    "                max_depth.append(self.left_child.get_depth())\n",
    "            if self.right_child():\n",
    "                max_depth.append(self.right_child.get_depth())                 \n",
    "            return max(max_depth)\n",
    "                 \n",
    "    def test(self,data):\n",
    "        #runs through the code and returns result of one point\n",
    "        if self.label:\n",
    "            return self.label\n",
    "        else:\n",
    "            if #data attribute > self.split_value\n",
    "                 #subset data based on the split value and attribute\n",
    "                 return self.right_child.test(data_new)\n",
    "            else:\n",
    "                 return self.left_child.test(data_new)\n",
    "        \n",
    "    def visualise(self):\n",
    "        #visualisation\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self):\n",
    "        #evaluation\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
