{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6dY4sYN5BhnF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import find_split as fs\n",
    "import evaluation as ev\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-59. -53. -51. -54. -45. -79. -87.   4.]\n",
      " [-66. -53. -59. -62. -69. -81. -79.   1.]\n",
      " [-41. -57. -63. -40. -73. -66. -65.   2.]\n",
      " [-62. -58. -52. -63. -50. -87. -88.   4.]\n",
      " [-63. -58. -64. -67. -74. -87. -87.   4.]]\n"
     ]
    }
   ],
   "source": [
    "#using the noisy dataset so we can see the effects of pruning\n",
    "data = np.loadtxt('noisy_dataset.txt')\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binarySearchTree:\n",
    "    def __init__(self, data, depth=0, label = None):\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.depth = depth+1\n",
    "        self.label = label\n",
    "        self.split_value = None\n",
    "        self.split_router = None\n",
    "        \n",
    "        #default value none, 0 for choosing not to prune, 1 for testing during pruning, 2 for permanently pruned\n",
    "        self.prune=None \n",
    "        \n",
    "        #set future prune value to most common label in data\n",
    "        self.prune_label=np.argmax(np.bincount([int(i) for i in data[:,-1]]))\n",
    "        \n",
    "        if len(np.unique(data[:,-1]))==1: #assuming last column is for labels\n",
    "            self.label = data[0,-1]\n",
    "        \n",
    "        else:\n",
    "            #not all samples have same label, do a split\n",
    "            # split router: router from [1,...,6]\n",
    "            # split_value: router value\n",
    "            split_router,split_value,temp_data=fs.find_split(data)\n",
    "            self.split_value=split_value\n",
    "            self.split_router=split_router\n",
    "            l_data=temp_data[0]\n",
    "            r_data=temp_data[1]\n",
    "             \n",
    "            #recursively search the tree, branching into 2 \n",
    "            self.left_child=binarySearchTree(l_data, self.depth)\n",
    "            self.right_child=binarySearchTree(r_data, self.depth)\n",
    "        \n",
    "    def get_max_depth(self):\n",
    "        #search each branch recursively and get max depth\n",
    "            max_depth=[self.depth]\n",
    "            if self.left_child:\n",
    "                max_depth.append(self.left_child.get_max_depth())\n",
    "            if self.right_child:\n",
    "                max_depth.append(self.right_child.get_max_depth())                 \n",
    "            return max(max_depth)\n",
    "        \n",
    "    def predict_one(self,data):\n",
    "        if self.prune:\n",
    "            if self.prune>0:\n",
    "                return np.array([self.prune_label])\n",
    "        if self.label:\n",
    "            return np.array([int(self.label)])\n",
    "        else:\n",
    "            if data[self.split_router-1]<=self.split_value:\n",
    "                return self.left_child.predict_one(data)\n",
    "\n",
    "            else:\n",
    "                return self.right_child.predict_one(data)  \n",
    "            \n",
    "    def prune_1_node(self,current_path=['parent']):\n",
    "        if self.label:\n",
    "            return\n",
    "        \n",
    "        #prune refers to whether or not we have tested it before\n",
    "        if self.prune!=None:\n",
    "            #if this node is already to be tested for pruning, we cannot be searching for any other nodes to prune!\n",
    "            if self.prune==1:\n",
    "            \n",
    "                raise ValueError('tried to prune two nodes')\n",
    "                \n",
    "            #else this means we have already pruned or chosen not to prune this branch, return True\n",
    "            return True\n",
    "        \n",
    "        if self.left_child.label and self.right_child.label:\n",
    "            print('set 1 to prune at path',current_path)\n",
    "            self.prune=1            \n",
    "            #set this node for pruning\n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            #recursively search for a prunable tree \n",
    "            #if False returned, we found a node to prune\n",
    "            #if True returned, we have pruned all possible nodes\n",
    "            l_path=current_path+['l']\n",
    "            l=self.left_child.prune_1_node(current_path=l_path) \n",
    "            if l==False:\n",
    "                return False\n",
    "            r_path=current_path+['r']\n",
    "            r=self.right_child.prune_1_node(current_path=r_path)\n",
    "            if r==False:\n",
    "                return False\n",
    "            \n",
    "\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def get_f1(self,data):\n",
    "        pred=self.predict(data[:,:-1]) \n",
    "        cm=ev.confusion_matrix(data[:,-1],pred)\n",
    "        m=ev.avg_recall_precision(cm)\n",
    "        return ev.f1_score(m[0],m[1])\n",
    "    \n",
    "    def set_prune_status(self,pruned=False):\n",
    "        \n",
    "        if self.label:\n",
    "            return\n",
    "        if self.prune:\n",
    "\n",
    "            if self.prune==0 or self.prune==2:\n",
    "                return       \n",
    "            if pruned==False:\n",
    "                self.prune=0\n",
    "                return\n",
    "            else:\n",
    "                self.prune=2\n",
    "                return\n",
    "        self.left_child.set_prune_status(pruned)\n",
    "        self.right_child.set_prune_status(pruned)\n",
    "                \n",
    "        \n",
    "    def prune_tree(self,data,print_path=False):\n",
    "        end=False\n",
    "        \n",
    "        val_error=self.get_f1(data)\n",
    "        while (not end):\n",
    "            #find node to prune\n",
    "            end=self.prune_1_node()\n",
    "            if print_path==True:\n",
    "                print('current f1:',val_error)\n",
    "            #validate and get error\n",
    "            new_f1=self.get_f1(data)\n",
    "            if print_path==True:            \n",
    "                print('new f1 score:',new_f1)\n",
    "            \n",
    "            #if error is better, prune or else dont prune\n",
    "            if new_f1>=val_error:\n",
    "                if print_path==True:                \n",
    "                    print('pruned 1!')\n",
    "                self.set_prune_status(pruned=True)\n",
    "                val_error=new_f1\n",
    "            else:\n",
    "                self.set_prune_status(pruned=False)\n",
    "                if print_path==True:                \n",
    "                    print('did not prune')\n",
    "            \n",
    "        \n",
    "            \n",
    "    def predict(self,data):\n",
    "        \n",
    "        data=np.squeeze(data)\n",
    "        if len(data.shape)>1:\n",
    "            return np.array([self.predict_one(i) for i in data]).flatten()\n",
    "        else:\n",
    "            return self.predict_one(data).flatten()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116, 10, 5, 12], [12, 126, 15, 14], [10, 12, 114, 10], [12, 5, 6, 121]]\n",
      "avg recall precision 0.79669488118472 0.79669488118472\n",
      "avg classification rate 0.795\n",
      "f1 0.79669488118472\n"
     ]
    }
   ],
   "source": [
    "#first, create a train and test set \n",
    "#evaluate on the test set to see pre-pruning results\n",
    "\n",
    "data2=data.copy()\n",
    "#shuffle data\n",
    "np.random.shuffle(data2)\n",
    "split=0.7\n",
    "train=data2[:int(len(data2)*split)]\n",
    "test=data2[int(len(data2)*split):]\n",
    "\n",
    "model=binarySearchTree(train)\n",
    "y_pred=model.predict(test[:,:-1])\n",
    "#evaluate\n",
    "cm=ev.confusion_matrix(test[:,-1],y_pred,plot=True)\n",
    "print(cm)\n",
    "r=ev.avg_recall_precision(cm)\n",
    "print('avg recall precision',r[0],r[1])\n",
    "print('avg classification rate',ev.avg_classification_rate(cm))\n",
    "print('f1',ev.f1_score(r[0],r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'l', 'l', 'r', 'r']\n",
      "current f1: 0.93852058201971\n",
      "new f1 score: 0.9380351451265061\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.93852058201971\n",
      "new f1 score: 0.9380247498840387\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'l', 'l', 'r', 'l']\n",
      "current f1: 0.93852058201971\n",
      "new f1 score: 0.9390389821508467\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9390389821508467\n",
      "new f1 score: 0.9390461681238274\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'l', 'r', 'r']\n",
      "current f1: 0.9390461681238274\n",
      "new f1 score: 0.9385607312306236\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'r', 'l']\n",
      "current f1: 0.9390461681238274\n",
      "new f1 score: 0.9385441600916988\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'r', 'r']\n",
      "current f1: 0.9390461681238274\n",
      "new f1 score: 0.9385441600916988\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'l', 'r', 'r', 'r']\n",
      "current f1: 0.9390461681238274\n",
      "new f1 score: 0.9395811393938889\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'r', 'l', 'l', 'l', 'r']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390957025006849\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'r', 'l', 'r', 'r']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9385607312306236\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'l', 'r', 'r', 'r', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9386102656074811\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'r', 'l', 'r', 'r']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390791313617604\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'l', 'r', 'r', 'r', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390781212852369\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'l', 'r', 'l', 'r']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.939070935312256\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'r', 'l', 'r', 'r', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9385607312306236\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'r', 'r', 'l', 'l', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390781212852369\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'l', 'r', 'r', 'r']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390791313617604\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'r', 'l', 'l', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390781212852369\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'l', 'r', 'l', 'l', 'r', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390957025006849\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9375731072653748\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9390781212852369\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'l', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9380751152975033\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9395811393938889\n",
      "new f1 score: 0.9400749513765133\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'l', 'r', 'r']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9385443391316152\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'r', 'r', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395719332678613\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'r', 'r', 'l', 'r', 'l', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395729433443847\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'l', 'r', 'r', 'r', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.939070935312256\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9400667553270091\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'r', 'r', 'l', 'l', 'l', 'l', 'r']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9400667553270091\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'l', 'r', 'r', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395647472948807\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'r', 'l', 'r', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395729433443847\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'l', 'r', 'r', 'r', 'l', 'r', 'l', 'r', 'r', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395729433443847\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9395729433443847\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'l', 'l', 'l', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9400749513765133\n",
      "new f1 score: 0.9405356210812883\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'l', 'l', 'l', 'l', 'r']\n",
      "current f1: 0.9405356210812883\n",
      "new f1 score: 0.9400182310266749\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'l', 'l', 'l', 'r', 'r', 'r', 'r', 'r', 'r']\n",
      "current f1: 0.9405356210812883\n",
      "new f1 score: 0.9400501841880844\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'l', 'l', 'r', 'r', 'r', 'r']\n",
      "current f1: 0.9405356210812883\n",
      "new f1 score: 0.9395295848639845\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'l', 'r', 'r']\n",
      "current f1: 0.9405356210812883\n",
      "new f1 score: 0.9405190499423638\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'l', 'l', 'r']\n",
      "current f1: 0.9405356210812883\n",
      "new f1 score: 0.9410044868355677\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'l', 'r']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9395481761559558\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'l', 'l', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405024788034391\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'l', 'r', 'r', 'l', 'l', 'r']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405190499423638\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'r', 'l', 'l', 'l', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405190499423638\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'l', 'r', 'l', 'r', 'r', 'l', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405024788034391\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9404942827539349\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'r', 'l', 'r']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405024788034391\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9379863781836562\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'l', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9409973008625868\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'l', 'l', 'r', 'l', 'r', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9405190499423638\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'l', 'l', 'r', 'l', 'r', 'r']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9404942827539349\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'l', 'r', 'l', 'l']\n",
      "current f1: 0.9410044868355677\n",
      "new f1 score: 0.9410396492664636\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'l', 'r', 'l', 'r', 'r', 'l']\n",
      "current f1: 0.9410396492664636\n",
      "new f1 score: 0.9405717935887077\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'r', 'l', 'r']\n",
      "current f1: 0.9410396492664636\n",
      "new f1 score: 0.9405366311578117\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'r', 'r', 'l', 'l', 'r']\n",
      "current f1: 0.9410396492664636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new f1 score: 0.9410406593429871\n",
      "pruned 1!\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'r', 'r', 'l', 'r', 'r', 'l']\n",
      "current f1: 0.9410406593429871\n",
      "new f1 score: 0.9405376412343353\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'r', 'r', 'r', 'l', 'r', 'l']\n",
      "current f1: 0.9410406593429871\n",
      "new f1 score: 0.9405396613873819\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'l', 'r', 'r', 'r', 'l', 'r', 'r', 'r', 'r']\n",
      "current f1: 0.9410406593429871\n",
      "new f1 score: 0.9405396613873819\n",
      "did not prune\n",
      "set 1 to prune at path ['parent', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']\n",
      "current f1: 0.9410406593429871\n",
      "new f1 score: 0.9420395095873101\n",
      "pruned 1!\n",
      "current f1: 0.9420395095873101\n",
      "new f1 score: 0.9420395095873101\n",
      "pruned 1!\n"
     ]
    }
   ],
   "source": [
    "#now prune the model\n",
    "#use print_path=False to not print\n",
    "model.prune_tree(data2,print_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121, 9, 3, 10], [9, 132, 13, 13], [8, 12, 118, 8], [10, 5, 6, 123]]\n",
      "avg recall precision 0.8247397131448378 0.8247397131448378\n",
      "avg classification rate 0.8233333333333334\n",
      "f1 0.8247397131448378\n"
     ]
    }
   ],
   "source": [
    "#now use the pruned model on the test set again\n",
    "\n",
    "y_pred=model.predict(test[:,:-1])\n",
    "#evaluate\n",
    "cm=ev.confusion_matrix(test[:,-1],y_pred,plot=True)\n",
    "print(cm)\n",
    "r=ev.avg_recall_precision(cm)\n",
    "print('avg recall precision',r[0],r[1])\n",
    "print('avg classification rate',ev.avg_classification_rate(cm))\n",
    "print('f1',ev.f1_score(r[0],r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as can be seen above, f1 score on validation set improved after pruning! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
